{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices.\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          03/25/93 Total time of visit (in minutes):\\n\n",
       "1                        6/18/85 Primary Care Doctor:\\n\n",
       "2     sshe plans to move as of 7/8/71 In-Home Servic...\n",
       "3                 7 on 9/27/75 Audit C Score Current:\\n\n",
       "4     2/6/96 sleep studyPain Treatment Pain Level (N...\n",
       "5                     .Per 7/06/79 Movement D/O note:\\n\n",
       "6     4, 5/18/78 Patient's thoughts about current su...\n",
       "7     10/24/89 CPT Code: 90801 - Psychiatric Diagnos...\n",
       "8                          3/7/86 SOS-10 Total Score:\\n\n",
       "9              (4/10/71)Score-1Audit C Score Current:\\n\n",
       "10    (5/11/85) Crt-1.96, BUN-26; AST/ALT-16/22; WBC...\n",
       "11                        4/09/75 SOS-10 Total Score:\\n\n",
       "12    8/01/98 Communication with referring physician...\n",
       "13    1/26/72 Communication with referring physician...\n",
       "14    5/24/1990 CPT Code: 90792: With medical servic...\n",
       "15    1/25/2011 CPT Code: 90792: With medical servic...\n",
       "16          4/12/82 Total time of visit (in minutes):\\n\n",
       "17         1; 10/13/1976 Audit C Score, Highest/Date:\\n\n",
       "18                  4, 4/24/98 Relevant Drug History:\\n\n",
       "19    ) 59 yo unemployed w referred by Urgent Care f...\n",
       "dtype: object"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "doc = []\n",
    "with open('dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.Series(doc)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9\n",
       "1       84\n",
       "2        2\n",
       "3       53\n",
       "4       28\n",
       "5      474\n",
       "6      153\n",
       "7       13\n",
       "8      129\n",
       "9       98\n",
       "10     111\n",
       "11     225\n",
       "12      31\n",
       "13     171\n",
       "14     191\n",
       "15     486\n",
       "16     335\n",
       "17     415\n",
       "18      36\n",
       "19     405\n",
       "20     323\n",
       "21     422\n",
       "22     375\n",
       "23     380\n",
       "24     345\n",
       "25      57\n",
       "26     481\n",
       "27     436\n",
       "28     104\n",
       "29     299\n",
       "30     162\n",
       "31     154\n",
       "32     402\n",
       "33      95\n",
       "34      73\n",
       "35     108\n",
       "36     156\n",
       "37     332\n",
       "38     182\n",
       "39      82\n",
       "40     351\n",
       "41     278\n",
       "42     214\n",
       "43     155\n",
       "44     223\n",
       "45     473\n",
       "46      49\n",
       "47     317\n",
       "48      11\n",
       "49     319\n",
       "50      40\n",
       "51     418\n",
       "52     165\n",
       "53     370\n",
       "54     382\n",
       "55       3\n",
       "56      50\n",
       "57     363\n",
       "58     219\n",
       "59     465\n",
       "60     342\n",
       "61     237\n",
       "62      23\n",
       "63     204\n",
       "64     258\n",
       "65     315\n",
       "66      27\n",
       "67      93\n",
       "68      17\n",
       "69     488\n",
       "70     303\n",
       "71     283\n",
       "72     395\n",
       "73     309\n",
       "74     419\n",
       "75     123\n",
       "76      19\n",
       "77     117\n",
       "78     232\n",
       "79      72\n",
       "80     189\n",
       "81     369\n",
       "82     493\n",
       "83     318\n",
       "84     239\n",
       "85     148\n",
       "86     105\n",
       "87     336\n",
       "88       6\n",
       "89     200\n",
       "90      81\n",
       "91      65\n",
       "92     434\n",
       "93     164\n",
       "94     378\n",
       "95     313\n",
       "96     495\n",
       "97     424\n",
       "98     398\n",
       "99       5\n",
       "100    254\n",
       "101    296\n",
       "102     75\n",
       "103    167\n",
       "104     21\n",
       "105    259\n",
       "106    499\n",
       "107    347\n",
       "108    150\n",
       "109     78\n",
       "110    340\n",
       "111    441\n",
       "112    361\n",
       "113    267\n",
       "114    221\n",
       "115    466\n",
       "116     39\n",
       "117    134\n",
       "118    197\n",
       "119    355\n",
       "120    430\n",
       "121     80\n",
       "122    444\n",
       "123    246\n",
       "124     85\n",
       "125    215\n",
       "126    263\n",
       "127     74\n",
       "128    403\n",
       "129    458\n",
       "130     16\n",
       "131     25\n",
       "132    127\n",
       "133    454\n",
       "134     70\n",
       "135     44\n",
       "136     59\n",
       "137    103\n",
       "138    112\n",
       "139    429\n",
       "140     88\n",
       "141    179\n",
       "142    470\n",
       "143    358\n",
       "144    205\n",
       "145    397\n",
       "146    294\n",
       "147    137\n",
       "148    295\n",
       "149     35\n",
       "150    438\n",
       "151    247\n",
       "152    209\n",
       "153     61\n",
       "154    107\n",
       "155    285\n",
       "156    175\n",
       "157     99\n",
       "158    455\n",
       "159     24\n",
       "160    275\n",
       "161    421\n",
       "162     48\n",
       "163    426\n",
       "164    489\n",
       "165    228\n",
       "166    136\n",
       "167     30\n",
       "168    274\n",
       "169     10\n",
       "170    178\n",
       "171      1\n",
       "172    447\n",
       "173    280\n",
       "174    185\n",
       "175    135\n",
       "176     69\n",
       "177    492\n",
       "178    199\n",
       "179    352\n",
       "180      8\n",
       "181    276\n",
       "182    230\n",
       "183    334\n",
       "184     96\n",
       "185     38\n",
       "186    368\n",
       "187    404\n",
       "188    261\n",
       "189    168\n",
       "190     29\n",
       "191    437\n",
       "192    423\n",
       "193     54\n",
       "194    284\n",
       "195    485\n",
       "196     68\n",
       "197     32\n",
       "198    349\n",
       "199     41\n",
       "200     63\n",
       "201    416\n",
       "202     55\n",
       "203    130\n",
       "204    116\n",
       "205     76\n",
       "206    462\n",
       "207    330\n",
       "208     37\n",
       "209    390\n",
       "210    256\n",
       "211    216\n",
       "212    174\n",
       "213    180\n",
       "214    476\n",
       "215    312\n",
       "216    265\n",
       "217    115\n",
       "218     71\n",
       "219    218\n",
       "220    202\n",
       "221    440\n",
       "222    385\n",
       "223    373\n",
       "224    210\n",
       "225     89\n",
       "226    149\n",
       "227     26\n",
       "228      7\n",
       "229    435\n",
       "230    482\n",
       "231    177\n",
       "232    157\n",
       "233    412\n",
       "234     22\n",
       "235    194\n",
       "236     14\n",
       "237    151\n",
       "238    233\n",
       "239    206\n",
       "240    245\n",
       "241    122\n",
       "242     94\n",
       "243    461\n",
       "244    226\n",
       "245     97\n",
       "246     91\n",
       "247     51\n",
       "248     33\n",
       "249    453\n",
       "250     67\n",
       "251     46\n",
       "252    322\n",
       "253     66\n",
       "254    399\n",
       "255    487\n",
       "256    138\n",
       "257     62\n",
       "258    211\n",
       "259     52\n",
       "260    269\n",
       "261    119\n",
       "262    100\n",
       "263    442\n",
       "264    310\n",
       "265    143\n",
       "266    301\n",
       "267    113\n",
       "268    478\n",
       "269    298\n",
       "270    272\n",
       "271    354\n",
       "272      0\n",
       "273    249\n",
       "274    192\n",
       "275     86\n",
       "276    172\n",
       "277    357\n",
       "278    331\n",
       "279    477\n",
       "280    450\n",
       "281    300\n",
       "282    163\n",
       "283    308\n",
       "284    196\n",
       "285     47\n",
       "286    133\n",
       "287    359\n",
       "288     64\n",
       "289     42\n",
       "290    409\n",
       "291    406\n",
       "292    483\n",
       "293    238\n",
       "294    193\n",
       "295    311\n",
       "296    140\n",
       "297    388\n",
       "298     56\n",
       "299    236\n",
       "300    372\n",
       "301    110\n",
       "302    248\n",
       "303     60\n",
       "304    181\n",
       "305    203\n",
       "306    326\n",
       "307     90\n",
       "308    169\n",
       "309    292\n",
       "310    479\n",
       "311    142\n",
       "312      4\n",
       "313    124\n",
       "314    324\n",
       "315    121\n",
       "316    131\n",
       "317    166\n",
       "318    468\n",
       "319    365\n",
       "320    213\n",
       "321     87\n",
       "322    353\n",
       "323    101\n",
       "324    333\n",
       "325    114\n",
       "326    459\n",
       "327     45\n",
       "328    338\n",
       "329     18\n",
       "330    222\n",
       "331    343\n",
       "332     20\n",
       "333    224\n",
       "334     12\n",
       "335     79\n",
       "336    387\n",
       "337    251\n",
       "338    120\n",
       "339    471\n",
       "340     77\n",
       "341    376\n",
       "342    432\n",
       "343    327\n",
       "344    384\n",
       "345    321\n",
       "346    212\n",
       "347    407\n",
       "348    266\n",
       "349    145\n",
       "350    201\n",
       "351    456\n",
       "352    305\n",
       "353    260\n",
       "354    420\n",
       "355    329\n",
       "356    392\n",
       "357    417\n",
       "358    190\n",
       "359    158\n",
       "360    443\n",
       "361     83\n",
       "362    374\n",
       "363    457\n",
       "364    125\n",
       "365    328\n",
       "366    159\n",
       "367    195\n",
       "368    147\n",
       "369    377\n",
       "370    367\n",
       "371    394\n",
       "372    494\n",
       "373    304\n",
       "374    446\n",
       "375     43\n",
       "376    262\n",
       "377    128\n",
       "378    102\n",
       "379    449\n",
       "380    184\n",
       "381    469\n",
       "382    452\n",
       "383    234\n",
       "384    362\n",
       "385    356\n",
       "386    144\n",
       "387    291\n",
       "388    484\n",
       "389    188\n",
       "390    414\n",
       "391     92\n",
       "392    350\n",
       "393    241\n",
       "394    306\n",
       "395    425\n",
       "396    281\n",
       "397    207\n",
       "398    126\n",
       "399    302\n",
       "400    146\n",
       "401    451\n",
       "402    498\n",
       "403    339\n",
       "404    250\n",
       "405    344\n",
       "406    346\n",
       "407    348\n",
       "408    496\n",
       "409    106\n",
       "410    118\n",
       "411    270\n",
       "412    433\n",
       "413    307\n",
       "414    173\n",
       "415    314\n",
       "416    410\n",
       "417    490\n",
       "418    252\n",
       "419    391\n",
       "420    277\n",
       "421    325\n",
       "422    264\n",
       "423    289\n",
       "424    160\n",
       "425    341\n",
       "426    132\n",
       "427    428\n",
       "428    337\n",
       "429    445\n",
       "430    497\n",
       "431    187\n",
       "432    183\n",
       "433    396\n",
       "434    271\n",
       "435    293\n",
       "436    400\n",
       "437    360\n",
       "438    297\n",
       "439    491\n",
       "440    371\n",
       "441    389\n",
       "442    386\n",
       "443    288\n",
       "444    379\n",
       "445    268\n",
       "446    472\n",
       "447    273\n",
       "448    287\n",
       "449    448\n",
       "450    176\n",
       "451    411\n",
       "452    408\n",
       "453    364\n",
       "454    242\n",
       "455     58\n",
       "456    467\n",
       "457    170\n",
       "458     15\n",
       "459    240\n",
       "460    316\n",
       "461    229\n",
       "462    217\n",
       "463    109\n",
       "464    227\n",
       "465    290\n",
       "466    460\n",
       "467    393\n",
       "468    282\n",
       "469     34\n",
       "470    220\n",
       "471    208\n",
       "472    243\n",
       "473    139\n",
       "474    320\n",
       "475    383\n",
       "476    244\n",
       "477    286\n",
       "478    480\n",
       "479    431\n",
       "480    279\n",
       "481    198\n",
       "482    381\n",
       "483    463\n",
       "484    366\n",
       "485    439\n",
       "486    255\n",
       "487    401\n",
       "488    475\n",
       "489    257\n",
       "490    152\n",
       "491    235\n",
       "492    464\n",
       "493    253\n",
       "494    427\n",
       "495    231\n",
       "496    141\n",
       "497    186\n",
       "498    161\n",
       "499    413\n",
       "dtype: int64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def date_sorter():\n",
    "    \n",
    "    pd.set_option('display.max_rows', 1000)\n",
    "    \n",
    "    # extract date information\n",
    "    # normalize columns to month, day, year cols=['0', '1', '2']\n",
    "    # merge data\n",
    "    # convert date to datetime\n",
    "    # sort\n",
    "    # return as series\n",
    "    \n",
    "    cols=['Month', 'Day', 'Year']\n",
    "    month_dict = dict({'Jan':1, 'January':1, 'Feb':2, 'February':2, 'Mar':3, 'March':3,\n",
    "                      'Apr':4, 'April':4, 'May':5, 'Jun':6, 'June':6, 'Jul':7, 'July':7,\n",
    "                      'Aug':8, 'August':8, 'Sep':9, 'September':9, 'Oct':10, 'October':10,\n",
    "                      'Nov':11, 'November':11, 'Dec':12, 'December':12,\n",
    "                       'Janaury':1, 'Decemeber':12})\n",
    "\n",
    "    \n",
    "    \n",
    "    # Step_1\n",
    "    # 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "    # need to fis year 19xx or 20xx. if two digits,  convert months to text\n",
    "    # make sure not to getxx/yy/zzz\n",
    "    date1a = df.str.extractall(r'(\\d{1,2})[/-](\\d{1,2})[/-](\\d{2})\\b')\n",
    "    date1b = df.str.extractall(r'(\\d{1,2})[/-](\\d{1,2})[/-](\\d{4})\\b')\n",
    "    date1a.columns = cols\n",
    "    date1b.columns = cols\n",
    "    # prepend years with 19\n",
    "    date1a['Year'] = '19' + date1a['Year'].astype(str)\n",
    "    #print(date1)\n",
    "    \n",
    "    \n",
    "    # Step_2\n",
    "    # Mar-20-2009; Mar 20, 2009; March 20, 2009; Mar. 20, 2009; Mar 20 2009;\n",
    "    # need to remove some extraneous . Take first 3 letters of month\n",
    "    date2 = df.str.extractall(r'((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*)[-. ]( *)(\\d{1,2})[-, ] *(\\d{4})\\b')\n",
    "    del date2[1]\n",
    "    date2.columns = cols\n",
    "    #print(date2)\n",
    "    \n",
    "    \n",
    "    # Step_3\n",
    "    # 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "    # need to swap month and day\n",
    "    date3 = df.str.extractall(r'(\\d{1,2}) ((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*)[-., ] *(\\d{4})\\b')\n",
    "    c = date3.columns\n",
    "    date3 = date3[c[np.r_[1, 0, 2:len(c)]]]\n",
    "    date3.columns = cols\n",
    "    #print(date3)\n",
    "    \n",
    "    \n",
    "    # Step_4a\n",
    "    # Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "    # there aren't any of these in the dataset\n",
    "    #date4.columns = cols\n",
    "    #print(date4)\n",
    "    \n",
    "    \n",
    "    # Step_4b\n",
    "    # merge first four unique cases\n",
    "    dates = pd.concat([date1a, date1b, date2, date3], ignore_index=False)\n",
    "    #print(dates)\n",
    "    \n",
    "    \n",
    "    # Step_5\n",
    "    # Feb 2009; Sep 2009; Oct 2010\n",
    "    # need to add day = 1, might need to exclude '20 Mar 2009'\n",
    "    # problem with 228\n",
    "    date5 = df.str.extractall(r'((?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*)[-., ] *(\\d{4})')\n",
    "    date5[2] = '1'\n",
    "    c = date5.columns\n",
    "    date5 = date5[c[np.r_[0, 2, 1]]]\n",
    "    date5.columns = cols\n",
    "    #print(date5)\n",
    "    # merge with dates\n",
    "    dates = pd.merge(dates, date5, left_index = True, right_index = True, how = 'outer')\n",
    "    dates1 = dates.loc[:228]\n",
    "    del dates1['Month_y']\n",
    "    del dates1['Day_y']\n",
    "    del dates1['Year_y']\n",
    "    dates1.columns = cols\n",
    "    dates2 = dates.loc[229:]\n",
    "    del dates2['Month_x']\n",
    "    del dates2['Day_x']\n",
    "    del dates2['Year_x']\n",
    "    dates2.columns = cols\n",
    "    dates = pd.concat([dates1, dates2], ignore_index=False)\n",
    "    #print(date)\n",
    "    \n",
    "    \n",
    "    # Step_6\n",
    "    # 6/2008; 12/2009\n",
    "    # need to add day (1), might need to exclude 4/3/09\n",
    "    # PROBLEM\n",
    "    date6 = df.str.extractall(r'(\\d{1,2})/(\\d{4})')\n",
    "    date6['Day'] = '1'\n",
    "    c = date6.columns\n",
    "    date6 = date6[c[np.r_[0, 2, 1]]]\n",
    "    date6.columns = cols\n",
    "    #print(date6)\n",
    "    # merge with dates\n",
    "    dates = pd.merge(dates, date6, left_index = True, right_index = True, how = 'outer')\n",
    "    dates1 = dates.loc[:341]\n",
    "    del dates1['Month_y']\n",
    "    del dates1['Day_y']\n",
    "    del dates1['Year_y']\n",
    "    dates1.columns = cols\n",
    "    dates2 = dates.loc[342:]\n",
    "    del dates2['Month_x']\n",
    "    del dates2['Day_x']\n",
    "    del dates2['Year_x']\n",
    "    dates2.columns = cols\n",
    "    dates = pd.concat([dates1, dates2], ignore_index=False)\n",
    "    #print(dates)\n",
    "    \n",
    "    \n",
    "    # Step 7\n",
    "    # 2009; 2010\n",
    "    # need to add 1/1\n",
    "    date7a = df.str.extractall(r'(19\\d{2})')\n",
    "    date7b = df.str.extractall(r'(20\\d{2})')\n",
    "    date7 = pd.concat([date7a, date7b], ignore_index=False)\n",
    "    date7[1] = '1'\n",
    "    date7[2] = '1'\n",
    "    c = date7.columns\n",
    "    date7 = date7[c[np.r_[2, 1, 0]]]\n",
    "    date7.columns = cols\n",
    "    #print(date7)\n",
    "    \n",
    "    # merge with dates\n",
    "    dates = pd.merge(dates, date7, left_index = True, right_index = True, how = 'outer')\n",
    "    #print(dates)\n",
    "    dates.Month_x.fillna(dates.Month_y, inplace=True)\n",
    "    dates.Day_x.fillna(dates.Day_y, inplace=True)\n",
    "    dates.Year_x.fillna(dates.Year_y, inplace=True)\n",
    "    del dates['Month_y']\n",
    "    del dates['Day_y']\n",
    "    del dates['Year_y']\n",
    "    dates.columns = cols       \n",
    "    #print(dates)\n",
    "    \n",
    "    \n",
    "    # Step 8 Create Datetime\n",
    "    # convert months to numbers\n",
    "    dates['Month'].replace(month_dict, inplace=True)\n",
    "    # add column for DateTime, convert columns to ints\n",
    "    dates['DateTime'] = dates[['Year', 'Month', 'Day']].astype(int).apply(lambda s : datetime.datetime(*s),axis = 1)\n",
    "    dates.sort_values(['DateTime'], ascending=[True], inplace=True)\n",
    "    #print(dates)\n",
    "    # get the index\n",
    "    output = pd.Series(dates.index.get_level_values(0))\n",
    "    #print(output)\n",
    "\n",
    "    return output\n",
    "\n",
    "date_sorter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
